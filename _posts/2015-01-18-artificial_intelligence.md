---
layout: post
title: Artificial Intelligence
tags:
- Tech
- Design
---
<center><img src="/images/ai.jpg" alt="artificial intelligence image" class="post_img"></center>
While scrolling my Twitter feed this morning, I came across this article that Wired posted: <a target="_blank" href="http://www.wired.com/2015/01/ai-arrived-really-worries-worlds-brightest-minds">"AI Has Arrived, and That Really Worries the World's Brightest Minds"</a>. The first thing I felt was relief. I was relieved to see that the "World's Brightest Minds" were looking into the future and thinking about the ways AI research could be dangerous and could be used in insidious ways. I was relieved to see Elon Musk, an incredibly forward-thinking, innovative man pledge to conduct AI research for good. I was relieved to see a robotics company vow to never build robots for military use. However, these are just two entities. AI is becoming more and more popular and it is in incredibly high demand by the top tech companies (Google, Facebook, Microsoft, Baidu), the best talents going to the company willing to pay the highest price. It wouldn't be shocking if militaries across the world begin putting their bids in.

Is it possible to build robots that feel empathy? Can empathy be taught? For something that is devoid of feelings from its conception, can it be taught to feel empathy? Something that even humans are not capable to always feel. Would we then be able to create something that perfects that ability?

It is crucial for scientists and designers working on AI research to consider these issues and create these products in an ethical manner.